{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2082f1b7",
   "metadata": {},
   "source": [
    "# Runtime Performance Comparison: Node.js vs Deno vs Bun\n",
    "\n",
    "This notebook provides a comprehensive comparison of Next.js application performance across three JavaScript runtimes:\n",
    "- **Node.js**: The traditional JavaScript runtime\n",
    "- **Deno**: A secure runtime for JavaScript and TypeScript  \n",
    "- **Bun**: A fast all-in-one JavaScript runtime\n",
    "\n",
    "## Overview\n",
    "\n",
    "We'll create identical Next.js applications for each runtime, containerize them using Docker, and monitor their CPU and memory usage patterns to determine which runtime performs best under different scenarios.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Docker and Docker Compose installed\n",
    "- Python 3.11+ with required packages\n",
    "- Sufficient system resources to run multiple containers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41677df",
   "metadata": {},
   "source": [
    "## 1. Setup Project Structure\n",
    "\n",
    "First, let's verify our project structure and import the necessary libraries for performance monitoring and data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a54d370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All libraries imported successfully!\n",
      "üìÅ Working directory: /app/notebooks\n",
      "üêç Python version: 3.11.14 (main, Oct  9 2025, 22:42:12) [GCC 14.2.0]\n",
      "üïê Current time: 2025-10-21 07:51:19\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "import threading\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Import our custom performance monitor\n",
    "sys.path.append('/app')\n",
    "from performance_monitor import PerformanceMonitor\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"üìÅ Working directory: {os.getcwd()}\")\n",
    "print(f\"üêç Python version: {sys.version}\")\n",
    "print(f\"üïê Current time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d98e161d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Checking project structure...\n",
      "‚ùå node-nextjs/ missing\n",
      "‚ùå deno-nextjs/ missing\n",
      "‚ùå bun-nextjs/ missing\n",
      "‚ùå monitoring/ missing\n",
      "‚ùå docker-compose.yml missing\n"
     ]
    }
   ],
   "source": [
    "# Verify project structure\n",
    "project_root = \"/Users/jabbo/node-vs-deno-vs-bun\"\n",
    "expected_dirs = [\"node-nextjs\", \"deno-nextjs\", \"bun-nextjs\", \"monitoring\"]\n",
    "\n",
    "print(\"üîç Checking project structure...\")\n",
    "for directory in expected_dirs:\n",
    "    path = os.path.join(project_root, directory)\n",
    "    if os.path.exists(path):\n",
    "        print(f\"‚úÖ {directory}/ exists\")\n",
    "        # List key files in each directory\n",
    "        files = os.listdir(path)\n",
    "        key_files = [f for f in files if f in ['package.json', 'deno.json', 'Dockerfile', 'next.config.js']]\n",
    "        if key_files:\n",
    "            print(f\"   üìÑ Key files: {', '.join(key_files)}\")\n",
    "    else:\n",
    "        print(f\"‚ùå {directory}/ missing\")\n",
    "\n",
    "# Check if docker-compose.yml exists\n",
    "compose_file = os.path.join(project_root, \"docker-compose.yml\")\n",
    "if os.path.exists(compose_file):\n",
    "    print(\"‚úÖ docker-compose.yml exists\")\n",
    "else:\n",
    "    print(\"‚ùå docker-compose.yml missing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0308ea",
   "metadata": {},
   "source": [
    "## 2. Create NextJS Applications\n",
    "\n",
    "Our project structure includes three identical Next.js applications, each configured for a different runtime:\n",
    "\n",
    "1. **node-nextjs/**: Traditional Node.js setup with npm\n",
    "2. **deno-nextjs/**: Deno setup with deno.json configuration  \n",
    "3. **bun-nextjs/**: Bun setup with native Bun package manager\n",
    "\n",
    "Each application runs on a different port:\n",
    "- Node.js: `http://localhost:3001`\n",
    "- Deno: `http://localhost:3002` \n",
    "- Bun: `http://localhost:3003`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7366296e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Runtime Configuration Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Package Manager</th>\n",
       "      <th>Port</th>\n",
       "      <th>Config File</th>\n",
       "      <th>Container Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Node.js</td>\n",
       "      <td>npm</td>\n",
       "      <td>3001</td>\n",
       "      <td>package.json</td>\n",
       "      <td>node-nextjs-app</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Deno</td>\n",
       "      <td>deno</td>\n",
       "      <td>3002</td>\n",
       "      <td>deno.json</td>\n",
       "      <td>deno-nextjs-app</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bun</td>\n",
       "      <td>bun</td>\n",
       "      <td>3003</td>\n",
       "      <td>package.json</td>\n",
       "      <td>bun-nextjs-app</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Runtime Package Manager  Port   Config File   Container Name\n",
       "0  Node.js             npm  3001  package.json  node-nextjs-app\n",
       "1     Deno            deno  3002     deno.json  deno-nextjs-app\n",
       "2      Bun             bun  3003  package.json   bun-nextjs-app"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Checking Next.js versions across runtimes:\n",
      "  node-nextjs: package.json not found\n",
      "  deno-nextjs: package.json not found\n",
      "  bun-nextjs: package.json not found\n"
     ]
    }
   ],
   "source": [
    "# Display configuration comparison\n",
    "configurations = {\n",
    "    \"Runtime\": [\"Node.js\", \"Deno\", \"Bun\"],\n",
    "    \"Package Manager\": [\"npm\", \"deno\", \"bun\"],\n",
    "    \"Port\": [3001, 3002, 3003],\n",
    "    \"Config File\": [\"package.json\", \"deno.json\", \"package.json\"],\n",
    "    \"Container Name\": [\"node-nextjs-app\", \"deno-nextjs-app\", \"bun-nextjs-app\"]\n",
    "}\n",
    "\n",
    "config_df = pd.DataFrame(configurations)\n",
    "print(\"üìã Runtime Configuration Summary:\")\n",
    "display(config_df)\n",
    "\n",
    "# Check package.json files to verify Next.js versions\n",
    "print(\"\\nüîç Checking Next.js versions across runtimes:\")\n",
    "for runtime in [\"node-nextjs\", \"deno-nextjs\", \"bun-nextjs\"]:\n",
    "    package_path = f\"{project_root}/{runtime}/package.json\"\n",
    "    if os.path.exists(package_path):\n",
    "        with open(package_path, 'r') as f:\n",
    "            package_data = json.load(f)\n",
    "            nextjs_version = package_data.get('dependencies', {}).get('next', 'Not found')\n",
    "            print(f\"  {runtime}: Next.js {nextjs_version}\")\n",
    "    else:\n",
    "        print(f\"  {runtime}: package.json not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d77e49",
   "metadata": {},
   "source": [
    "## 3. Generate Dockerfiles for Each Runtime\n",
    "\n",
    "Each runtime has its own optimized Dockerfile:\n",
    "\n",
    "- **Node.js**: Uses `node:18-alpine` base image with npm\n",
    "- **Deno**: Uses `denoland/deno:1.37.0` with native Deno commands\n",
    "- **Bun**: Uses `oven/bun:1.0.7` with native Bun commands\n",
    "\n",
    "All containers are configured for production builds with the `standalone` output mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "491f8bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üê≥ Dockerfile Configuration Comparison:\n",
      "\n",
      "‚ùå /Users/jabbo/node-vs-deno-vs-bun/node-nextjs/Dockerfile not found\n",
      "‚ùå /Users/jabbo/node-vs-deno-vs-bun/deno-nextjs/Dockerfile not found\n",
      "‚ùå /Users/jabbo/node-vs-deno-vs-bun/bun-nextjs/Dockerfile not found\n"
     ]
    }
   ],
   "source": [
    "# Display Dockerfile comparison\n",
    "print(\"üê≥ Dockerfile Configuration Comparison:\\n\")\n",
    "\n",
    "dockerfiles = {\n",
    "    \"node-nextjs\": f\"{project_root}/node-nextjs/Dockerfile\",\n",
    "    \"deno-nextjs\": f\"{project_root}/deno-nextjs/Dockerfile\", \n",
    "    \"bun-nextjs\": f\"{project_root}/bun-nextjs/Dockerfile\"\n",
    "}\n",
    "\n",
    "dockerfile_info = []\n",
    "for runtime, dockerfile_path in dockerfiles.items():\n",
    "    if os.path.exists(dockerfile_path):\n",
    "        with open(dockerfile_path, 'r') as f:\n",
    "            content = f.read()\n",
    "            \n",
    "        # Extract key information\n",
    "        lines = content.split('\\n')\n",
    "        base_image = next((line.split()[1] for line in lines if line.startswith('FROM')), 'Not found')\n",
    "        expose_port = next((line.split()[1] for line in lines if line.startswith('EXPOSE')), 'Not found')\n",
    "        \n",
    "        dockerfile_info.append({\n",
    "            'Runtime': runtime,\n",
    "            'Base Image': base_image,\n",
    "            'Exposed Port': expose_port,\n",
    "            'File Size (bytes)': len(content)\n",
    "        })\n",
    "        \n",
    "        print(f\"üìÑ {runtime}/Dockerfile:\")\n",
    "        print(f\"   Base Image: {base_image}\")\n",
    "        print(f\"   Exposed Port: {expose_port}\")\n",
    "        print(f\"   File Size: {len(content)} bytes\")\n",
    "        print()\n",
    "    else:\n",
    "        print(f\"‚ùå {dockerfile_path} not found\")\n",
    "\n",
    "# Create DataFrame for comparison\n",
    "if dockerfile_info:\n",
    "    dockerfile_df = pd.DataFrame(dockerfile_info)\n",
    "    display(dockerfile_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eaa0559",
   "metadata": {},
   "source": [
    "## 4. Create Docker Compose Configuration\n",
    "\n",
    "The Docker Compose file orchestrates all three Next.js applications plus our monitoring container:\n",
    "\n",
    "- **Services**: node-nextjs, deno-nextjs, bun-nextjs, monitoring\n",
    "- **Network**: All containers share the `nextjs-comparison` network\n",
    "- **Health Checks**: Each app container has HTTP health checks\n",
    "- **Volumes**: Monitoring container has access to Docker socket and shared data volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d6f72a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Checking Docker environment:\n",
      "‚úÖ Docker: Docker version 26.1.5+dfsg1, build a72d7cd\n",
      "‚ùå Docker Compose command not found\n",
      "\n",
      "‚ö†Ô∏è  Docker environment setup required before proceeding\n",
      "\n",
      "‚ùå /Users/jabbo/node-vs-deno-vs-bun/docker-compose.yml not found\n"
     ]
    }
   ],
   "source": [
    "# Check Docker and Docker Compose availability\n",
    "def check_docker():\n",
    "    try:\n",
    "        result = subprocess.run(['docker', '--version'], capture_output=True, text=True)\n",
    "        if result.returncode == 0:\n",
    "            print(f\"‚úÖ Docker: {result.stdout.strip()}\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"‚ùå Docker not found\")\n",
    "            return False\n",
    "    except FileNotFoundError:\n",
    "        print(\"‚ùå Docker command not found\")\n",
    "        return False\n",
    "\n",
    "def check_docker_compose():\n",
    "    try:\n",
    "        result = subprocess.run(['docker-compose', '--version'], capture_output=True, text=True)\n",
    "        if result.returncode == 0:\n",
    "            print(f\"‚úÖ Docker Compose: {result.stdout.strip()}\")\n",
    "            return True\n",
    "        else:\n",
    "            # Try docker compose (newer syntax)\n",
    "            result = subprocess.run(['docker', 'compose', 'version'], capture_output=True, text=True)\n",
    "            if result.returncode == 0:\n",
    "                print(f\"‚úÖ Docker Compose: {result.stdout.strip()}\")\n",
    "                return True\n",
    "            else:\n",
    "                print(\"‚ùå Docker Compose not found\")\n",
    "                return False\n",
    "    except FileNotFoundError:\n",
    "        print(\"‚ùå Docker Compose command not found\")\n",
    "        return False\n",
    "\n",
    "print(\"üîç Checking Docker environment:\")\n",
    "docker_available = check_docker()\n",
    "compose_available = check_docker_compose()\n",
    "\n",
    "if docker_available and compose_available:\n",
    "    print(\"\\n‚úÖ Docker environment is ready!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Docker environment setup required before proceeding\")\n",
    "\n",
    "# Display docker-compose.yml structure\n",
    "compose_path = f\"{project_root}/docker-compose.yml\"\n",
    "if os.path.exists(compose_path):\n",
    "    print(f\"\\nüìÑ Docker Compose file structure:\")\n",
    "    with open(compose_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    # Show service definitions\n",
    "    services = []\n",
    "    for line in lines:\n",
    "        if line.strip().endswith(':') and not line.startswith(' ') and 'services' not in line:\n",
    "            service_name = line.strip().rstrip(':')\n",
    "            if service_name not in ['version', 'networks']:\n",
    "                services.append(service_name)\n",
    "    \n",
    "    print(f\"   Services defined: {', '.join(services)}\")\n",
    "    print(f\"   Total lines: {len(lines)}\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå {compose_path} not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4f7ab7",
   "metadata": {},
   "source": [
    "## 5. Build Performance Monitoring Script\n",
    "\n",
    "Our performance monitoring system includes:\n",
    "\n",
    "- **PerformanceMonitor class**: Monitors Docker containers using the Docker API\n",
    "- **Metrics collection**: CPU percentage, memory usage (MB and %), container health\n",
    "- **Data persistence**: Automatic saving to JSON and CSV formats\n",
    "- **Real-time monitoring**: Configurable interval-based collection\n",
    "- **System-wide metrics**: Overall system resource usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f28493f",
   "metadata": {},
   "outputs": [
    {
     "ename": "DockerException",
     "evalue": "Error while fetching server API version: Not supported URL scheme http+docker",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mURLSchemeUnknown\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/requests/adapters.py:633\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    632\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m633\u001b[39m     conn = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_connection_with_tls_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    634\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcert\u001b[49m\n\u001b[32m    635\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    636\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m LocationValueError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/requests/adapters.py:489\u001b[39m, in \u001b[36mHTTPAdapter.get_connection_with_tls_context\u001b[39m\u001b[34m(self, request, verify, proxies, cert)\u001b[39m\n\u001b[32m    487\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    488\u001b[39m     \u001b[38;5;66;03m# Only scheme should be lower case\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m     conn = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpoolmanager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnection_from_host\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhost_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpool_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpool_kwargs\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m conn\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/urllib3/poolmanager.py:319\u001b[39m, in \u001b[36mPoolManager.connection_from_host\u001b[39m\u001b[34m(self, host, port, scheme, pool_kwargs)\u001b[39m\n\u001b[32m    317\u001b[39m request_context[\u001b[33m\"\u001b[39m\u001b[33mhost\u001b[39m\u001b[33m\"\u001b[39m] = host\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconnection_from_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest_context\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/urllib3/poolmanager.py:341\u001b[39m, in \u001b[36mPoolManager.connection_from_context\u001b[39m\u001b[34m(self, request_context)\u001b[39m\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pool_key_constructor:\n\u001b[32m--> \u001b[39m\u001b[32m341\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m URLSchemeUnknown(scheme)\n\u001b[32m    342\u001b[39m pool_key = pool_key_constructor(request_context)\n",
      "\u001b[31mURLSchemeUnknown\u001b[39m: Not supported URL scheme http+docker",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mInvalidURL\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/docker/api/client.py:214\u001b[39m, in \u001b[36mAPIClient._retrieve_server_version\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mversion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_version\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mApiVersion\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/docker/api/daemon.py:181\u001b[39m, in \u001b[36mDaemonApiMixin.version\u001b[39m\u001b[34m(self, api_version)\u001b[39m\n\u001b[32m    180\u001b[39m url = \u001b[38;5;28mself\u001b[39m._url(\u001b[33m\"\u001b[39m\u001b[33m/version\u001b[39m\u001b[33m\"\u001b[39m, versioned_api=api_version)\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m, json=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/docker/utils/decorators.py:46\u001b[39m, in \u001b[36mupdate_headers.<locals>.inner\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     45\u001b[39m         kwargs[\u001b[33m'\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m'\u001b[39m].update(\u001b[38;5;28mself\u001b[39m._general_configs[\u001b[33m'\u001b[39m\u001b[33mHttpHeaders\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/docker/api/client.py:237\u001b[39m, in \u001b[36mAPIClient._get\u001b[39m\u001b[34m(self, url, **kwargs)\u001b[39m\n\u001b[32m    235\u001b[39m \u001b[38;5;129m@update_headers\u001b[39m\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get\u001b[39m(\u001b[38;5;28mself\u001b[39m, url, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_set_request_timeout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/requests/sessions.py:602\u001b[39m, in \u001b[36mSession.get\u001b[39m\u001b[34m(self, url, **kwargs)\u001b[39m\n\u001b[32m    601\u001b[39m kwargs.setdefault(\u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m602\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGET\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/requests/adapters.py:637\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    636\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m LocationValueError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m637\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidURL(e, request=request)\n\u001b[32m    639\u001b[39m \u001b[38;5;28mself\u001b[39m.cert_verify(conn, request.url, verify, cert)\n",
      "\u001b[31mInvalidURL\u001b[39m: Not supported URL scheme http+docker",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mDockerException\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Initialize performance monitor\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m monitor = \u001b[43mPerformanceMonitor\u001b[49m\u001b[43m(\u001b[49m\u001b[43minterval\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Monitor every 5 seconds\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müîß Performance Monitor Configuration:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   Monitoring interval: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmonitor.interval\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m seconds\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/app/performance_monitor.py:23\u001b[39m, in \u001b[36mPerformanceMonitor.__init__\u001b[39m\u001b[34m(self, interval)\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[33;03mInitialize the performance monitor\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[33;03m\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[33;03m    interval: Monitoring interval in seconds\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;28mself\u001b[39m.interval = interval\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[38;5;28mself\u001b[39m.client = \u001b[43mdocker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[38;5;28mself\u001b[39m.data = []\n\u001b[32m     25\u001b[39m \u001b[38;5;28mself\u001b[39m.running = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/docker/client.py:96\u001b[39m, in \u001b[36mDockerClient.from_env\u001b[39m\u001b[34m(cls, **kwargs)\u001b[39m\n\u001b[32m     94\u001b[39m version = kwargs.pop(\u001b[33m'\u001b[39m\u001b[33mversion\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     95\u001b[39m use_ssh_client = kwargs.pop(\u001b[33m'\u001b[39m\u001b[33muse_ssh_client\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_pool_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_pool_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m    \u001b[49m\u001b[43mversion\u001b[49m\u001b[43m=\u001b[49m\u001b[43mversion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_ssh_client\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_ssh_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs_from_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/docker/client.py:45\u001b[39m, in \u001b[36mDockerClient.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m     \u001b[38;5;28mself\u001b[39m.api = \u001b[43mAPIClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/docker/api/client.py:197\u001b[39m, in \u001b[36mAPIClient.__init__\u001b[39m\u001b[34m(self, base_url, version, timeout, tls, user_agent, num_pools, credstore_env, use_ssh_client, max_pool_size)\u001b[39m\n\u001b[32m    192\u001b[39m \u001b[38;5;66;03m# version detection needs to be after unix adapter mounting\u001b[39;00m\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m version \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    194\u001b[39m                         version,\n\u001b[32m    195\u001b[39m                         \u001b[38;5;28mstr\u001b[39m\n\u001b[32m    196\u001b[39m                         ) \u001b[38;5;129;01mand\u001b[39;00m version.lower() == \u001b[33m'\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m     \u001b[38;5;28mself\u001b[39m._version = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_retrieve_server_version\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    199\u001b[39m     \u001b[38;5;28mself\u001b[39m._version = version\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/docker/api/client.py:221\u001b[39m, in \u001b[36mAPIClient._retrieve_server_version\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m DockerException(\n\u001b[32m    217\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mInvalid response from docker daemon: key \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mApiVersion\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    218\u001b[39m         \u001b[33m'\u001b[39m\u001b[33m is missing.\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    219\u001b[39m     )\n\u001b[32m    220\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m DockerException(\n\u001b[32m    222\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mError while fetching server API version: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    223\u001b[39m     )\n",
      "\u001b[31mDockerException\u001b[39m: Error while fetching server API version: Not supported URL scheme http+docker"
     ]
    }
   ],
   "source": [
    "# Initialize performance monitor\n",
    "monitor = PerformanceMonitor(interval=5)  # Monitor every 5 seconds\n",
    "\n",
    "print(\"üîß Performance Monitor Configuration:\")\n",
    "print(f\"   Monitoring interval: {monitor.interval} seconds\")\n",
    "print(f\"   Target containers: {list(monitor.containers.keys())}\")\n",
    "print(f\"   Data storage path: /app/data/\")\n",
    "\n",
    "# Test monitor connectivity\n",
    "print(\"\\nüîç Testing Docker connectivity:\")\n",
    "try:\n",
    "    import docker\n",
    "    client = docker.from_env()\n",
    "    containers = client.containers.list()\n",
    "    print(f\"   ‚úÖ Docker client connected\")\n",
    "    print(f\"   üì¶ Currently running containers: {len(containers)}\")\n",
    "    \n",
    "    for container in containers:\n",
    "        print(f\"     - {container.name}: {container.status}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"   ‚ùå Docker connection failed: {e}\")\n",
    "\n",
    "# Show monitor methods\n",
    "print(\"\\nüìã Available monitoring methods:\")\n",
    "methods = [method for method in dir(monitor) if not method.startswith('_') and callable(getattr(monitor, method))]\n",
    "for method in methods[:10]:  # Show first 10 methods\n",
    "    print(f\"   - {method}()\")\n",
    "    \n",
    "print(f\"   ... and {len(methods)-10} more methods\" if len(methods) > 10 else \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69aee78d",
   "metadata": {},
   "source": [
    "## 6. Run Docker Containers and Collect Metrics\n",
    "\n",
    "This section will start the Docker containers and begin performance monitoring. We'll:\n",
    "\n",
    "1. **Build and start all containers** using Docker Compose\n",
    "2. **Wait for containers to be healthy** before starting monitoring\n",
    "3. **Collect performance metrics** for a specified duration\n",
    "4. **Save the data** for analysis\n",
    "\n",
    "**‚ö†Ô∏è Important**: This step requires the containers to be running. If you're running this notebook inside the monitoring container, the other containers should already be started via Docker Compose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e7f2355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Checking container status:\n"
     ]
    },
    {
     "ename": "DockerException",
     "evalue": "Error while fetching server API version: Not supported URL scheme http+docker",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mURLSchemeUnknown\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/requests/adapters.py:633\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    632\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m633\u001b[39m     conn = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_connection_with_tls_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    634\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcert\u001b[49m\n\u001b[32m    635\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    636\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m LocationValueError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/requests/adapters.py:489\u001b[39m, in \u001b[36mHTTPAdapter.get_connection_with_tls_context\u001b[39m\u001b[34m(self, request, verify, proxies, cert)\u001b[39m\n\u001b[32m    487\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    488\u001b[39m     \u001b[38;5;66;03m# Only scheme should be lower case\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m     conn = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpoolmanager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnection_from_host\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhost_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpool_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpool_kwargs\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m conn\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/urllib3/poolmanager.py:319\u001b[39m, in \u001b[36mPoolManager.connection_from_host\u001b[39m\u001b[34m(self, host, port, scheme, pool_kwargs)\u001b[39m\n\u001b[32m    317\u001b[39m request_context[\u001b[33m\"\u001b[39m\u001b[33mhost\u001b[39m\u001b[33m\"\u001b[39m] = host\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconnection_from_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest_context\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/urllib3/poolmanager.py:341\u001b[39m, in \u001b[36mPoolManager.connection_from_context\u001b[39m\u001b[34m(self, request_context)\u001b[39m\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pool_key_constructor:\n\u001b[32m--> \u001b[39m\u001b[32m341\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m URLSchemeUnknown(scheme)\n\u001b[32m    342\u001b[39m pool_key = pool_key_constructor(request_context)\n",
      "\u001b[31mURLSchemeUnknown\u001b[39m: Not supported URL scheme http+docker",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mInvalidURL\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/docker/api/client.py:214\u001b[39m, in \u001b[36mAPIClient._retrieve_server_version\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mversion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_version\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mApiVersion\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/docker/api/daemon.py:181\u001b[39m, in \u001b[36mDaemonApiMixin.version\u001b[39m\u001b[34m(self, api_version)\u001b[39m\n\u001b[32m    180\u001b[39m url = \u001b[38;5;28mself\u001b[39m._url(\u001b[33m\"\u001b[39m\u001b[33m/version\u001b[39m\u001b[33m\"\u001b[39m, versioned_api=api_version)\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m, json=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/docker/utils/decorators.py:46\u001b[39m, in \u001b[36mupdate_headers.<locals>.inner\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     45\u001b[39m         kwargs[\u001b[33m'\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m'\u001b[39m].update(\u001b[38;5;28mself\u001b[39m._general_configs[\u001b[33m'\u001b[39m\u001b[33mHttpHeaders\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/docker/api/client.py:237\u001b[39m, in \u001b[36mAPIClient._get\u001b[39m\u001b[34m(self, url, **kwargs)\u001b[39m\n\u001b[32m    235\u001b[39m \u001b[38;5;129m@update_headers\u001b[39m\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get\u001b[39m(\u001b[38;5;28mself\u001b[39m, url, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_set_request_timeout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/requests/sessions.py:602\u001b[39m, in \u001b[36mSession.get\u001b[39m\u001b[34m(self, url, **kwargs)\u001b[39m\n\u001b[32m    601\u001b[39m kwargs.setdefault(\u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m602\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGET\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/requests/adapters.py:637\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    636\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m LocationValueError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m637\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidURL(e, request=request)\n\u001b[32m    639\u001b[39m \u001b[38;5;28mself\u001b[39m.cert_verify(conn, request.url, verify, cert)\n",
      "\u001b[31mInvalidURL\u001b[39m: Not supported URL scheme http+docker",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mDockerException\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# Check current container status\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müîç Checking container status:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m status = \u001b[43mcheck_container_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m status_df_data = []\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, info \u001b[38;5;129;01min\u001b[39;00m status.items():\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mcheck_container_status\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Check the status of all target containers\"\"\"\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdocker\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m client = \u001b[43mdocker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m container_status = {}\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m container_name \u001b[38;5;129;01min\u001b[39;00m monitor.containers.keys():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/docker/client.py:96\u001b[39m, in \u001b[36mDockerClient.from_env\u001b[39m\u001b[34m(cls, **kwargs)\u001b[39m\n\u001b[32m     94\u001b[39m version = kwargs.pop(\u001b[33m'\u001b[39m\u001b[33mversion\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     95\u001b[39m use_ssh_client = kwargs.pop(\u001b[33m'\u001b[39m\u001b[33muse_ssh_client\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_pool_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_pool_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m    \u001b[49m\u001b[43mversion\u001b[49m\u001b[43m=\u001b[49m\u001b[43mversion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_ssh_client\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_ssh_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs_from_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/docker/client.py:45\u001b[39m, in \u001b[36mDockerClient.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m     \u001b[38;5;28mself\u001b[39m.api = \u001b[43mAPIClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/docker/api/client.py:197\u001b[39m, in \u001b[36mAPIClient.__init__\u001b[39m\u001b[34m(self, base_url, version, timeout, tls, user_agent, num_pools, credstore_env, use_ssh_client, max_pool_size)\u001b[39m\n\u001b[32m    192\u001b[39m \u001b[38;5;66;03m# version detection needs to be after unix adapter mounting\u001b[39;00m\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m version \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    194\u001b[39m                         version,\n\u001b[32m    195\u001b[39m                         \u001b[38;5;28mstr\u001b[39m\n\u001b[32m    196\u001b[39m                         ) \u001b[38;5;129;01mand\u001b[39;00m version.lower() == \u001b[33m'\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m     \u001b[38;5;28mself\u001b[39m._version = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_retrieve_server_version\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    199\u001b[39m     \u001b[38;5;28mself\u001b[39m._version = version\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/docker/api/client.py:221\u001b[39m, in \u001b[36mAPIClient._retrieve_server_version\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m DockerException(\n\u001b[32m    217\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mInvalid response from docker daemon: key \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mApiVersion\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    218\u001b[39m         \u001b[33m'\u001b[39m\u001b[33m is missing.\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    219\u001b[39m     )\n\u001b[32m    220\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m DockerException(\n\u001b[32m    222\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mError while fetching server API version: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    223\u001b[39m     )\n",
      "\u001b[31mDockerException\u001b[39m: Error while fetching server API version: Not supported URL scheme http+docker"
     ]
    }
   ],
   "source": [
    "# Check container status and health\n",
    "def check_container_status():\n",
    "    \"\"\"Check the status of all target containers\"\"\"\n",
    "    import docker\n",
    "    client = docker.from_env()\n",
    "    \n",
    "    container_status = {}\n",
    "    for container_name in monitor.containers.keys():\n",
    "        try:\n",
    "            container = client.containers.get(container_name)\n",
    "            container_status[container_name] = {\n",
    "                'status': container.status,\n",
    "                'health': getattr(container.attrs['State'], 'Health', {}).get('Status', 'N/A'),\n",
    "                'ports': container.ports\n",
    "            }\n",
    "        except docker.errors.NotFound:\n",
    "            container_status[container_name] = {\n",
    "                'status': 'not found',\n",
    "                'health': 'N/A',\n",
    "                'ports': {}\n",
    "            }\n",
    "        except Exception as e:\n",
    "            container_status[container_name] = {\n",
    "                'status': f'error: {e}',\n",
    "                'health': 'N/A',\n",
    "                'ports': {}\n",
    "            }\n",
    "    \n",
    "    return container_status\n",
    "\n",
    "# Check current container status\n",
    "print(\"üîç Checking container status:\")\n",
    "status = check_container_status()\n",
    "\n",
    "status_df_data = []\n",
    "for name, info in status.items():\n",
    "    status_df_data.append({\n",
    "        'Container': name,\n",
    "        'Status': info['status'],\n",
    "        'Health': info['health'],\n",
    "        'Ports': str(info['ports']) if info['ports'] else 'None'\n",
    "    })\n",
    "\n",
    "status_df = pd.DataFrame(status_df_data)\n",
    "display(status_df)\n",
    "\n",
    "# Check if containers are ready for monitoring\n",
    "ready_containers = [name for name, info in status.items() if info['status'] == 'running']\n",
    "print(f\"\\nüìä Containers ready for monitoring: {len(ready_containers)}/{len(monitor.containers)}\")\n",
    "\n",
    "if len(ready_containers) < len(monitor.containers):\n",
    "    print(\"‚ö†Ô∏è  Some containers are not running. You may need to start them with:\")\n",
    "    print(\"   docker-compose up -d\")\n",
    "else:\n",
    "    print(\"‚úÖ All containers are running and ready for monitoring!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1413e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive monitoring controls\n",
    "monitoring_duration = widgets.IntSlider(\n",
    "    value=60,\n",
    "    min=30,\n",
    "    max=300,\n",
    "    step=10,\n",
    "    description='Duration (s):',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "monitoring_interval = widgets.IntSlider(\n",
    "    value=5,\n",
    "    min=1,\n",
    "    max=30,\n",
    "    step=1,\n",
    "    description='Interval (s):',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "start_button = widgets.Button(\n",
    "    description='Start Monitoring',\n",
    "    disabled=False,\n",
    "    button_style='success',\n",
    "    tooltip='Start performance monitoring',\n",
    "    icon='play'\n",
    ")\n",
    "\n",
    "stop_button = widgets.Button(\n",
    "    description='Stop Monitoring',\n",
    "    disabled=True,\n",
    "    button_style='danger',\n",
    "    tooltip='Stop performance monitoring',\n",
    "    icon='stop'\n",
    ")\n",
    "\n",
    "output_widget = widgets.Output()\n",
    "\n",
    "# Monitoring state\n",
    "monitoring_active = False\n",
    "monitoring_thread = None\n",
    "\n",
    "def start_monitoring(button):\n",
    "    global monitoring_active, monitoring_thread\n",
    "    \n",
    "    if monitoring_active:\n",
    "        return\n",
    "    \n",
    "    # Update monitor settings\n",
    "    monitor.interval = monitoring_interval.value\n",
    "    \n",
    "    # Disable start button, enable stop button\n",
    "    start_button.disabled = True\n",
    "    stop_button.disabled = False\n",
    "    \n",
    "    with output_widget:\n",
    "        clear_output(wait=True)\n",
    "        print(f\"üöÄ Starting monitoring for {monitoring_duration.value} seconds...\")\n",
    "        print(f\"üìä Monitoring interval: {monitoring_interval.value} seconds\")\n",
    "        print(\"üîÑ Monitoring in progress...\")\n",
    "    \n",
    "    monitoring_active = True\n",
    "    \n",
    "    # Start monitoring in a separate thread\n",
    "    def monitor_task():\n",
    "        monitor.start_monitoring(duration=monitoring_duration.value)\n",
    "        \n",
    "        # Update UI when done\n",
    "        start_button.disabled = False\n",
    "        stop_button.disabled = True\n",
    "        \n",
    "        with output_widget:\n",
    "            print(\"‚úÖ Monitoring completed!\")\n",
    "            print(f\"üìà Collected {len(monitor.data)} data points\")\n",
    "    \n",
    "    monitoring_thread = threading.Thread(target=monitor_task)\n",
    "    monitoring_thread.daemon = True\n",
    "    monitoring_thread.start()\n",
    "\n",
    "def stop_monitoring(button):\n",
    "    global monitoring_active\n",
    "    \n",
    "    if not monitoring_active:\n",
    "        return\n",
    "    \n",
    "    monitor.running = False\n",
    "    monitoring_active = False\n",
    "    \n",
    "    # Update buttons\n",
    "    start_button.disabled = False\n",
    "    stop_button.disabled = True\n",
    "    \n",
    "    with output_widget:\n",
    "        print(\"üõë Monitoring stopped by user\")\n",
    "        print(f\"üìà Collected {len(monitor.data)} data points\")\n",
    "\n",
    "start_button.on_click(start_monitoring)\n",
    "stop_button.on_click(stop_monitoring)\n",
    "\n",
    "# Display controls\n",
    "print(\"üéõÔ∏è  Monitoring Controls:\")\n",
    "display(widgets.VBox([\n",
    "    widgets.HBox([monitoring_duration, monitoring_interval]),\n",
    "    widgets.HBox([start_button, stop_button]),\n",
    "    output_widget\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a36dc67",
   "metadata": {},
   "source": [
    "## 7. Analyze Performance Data\n",
    "\n",
    "After monitoring, we'll analyze the collected performance data to understand:\n",
    "\n",
    "- **CPU Usage Patterns**: How each runtime utilizes CPU resources\n",
    "- **Memory Consumption**: Memory usage patterns and efficiency  \n",
    "- **Resource Stability**: Consistency of resource usage over time\n",
    "- **Health Status**: Application availability and responsiveness\n",
    "- **Comparative Performance**: Direct comparisons between runtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346f5318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and analyze performance data\n",
    "def load_latest_data():\n",
    "    \"\"\"Load the most recent performance data\"\"\"\n",
    "    data_dir = \"/app/data\"\n",
    "    \n",
    "    if not os.path.exists(data_dir):\n",
    "        print(\"‚ùå Data directory not found\")\n",
    "        return None\n",
    "    \n",
    "    # Find the most recent CSV file\n",
    "    csv_files = [f for f in os.listdir(data_dir) if f.endswith('.csv')]\n",
    "    \n",
    "    if not csv_files:\n",
    "        # Try to get data from monitor if available\n",
    "        if hasattr(monitor, 'data') and monitor.data:\n",
    "            print(\"üìä Using data from current monitoring session\")\n",
    "            return monitor.get_dataframe()\n",
    "        else:\n",
    "            print(\"‚ùå No performance data found\")\n",
    "            return None\n",
    "    \n",
    "    # Get the most recent file\n",
    "    latest_file = max(csv_files, key=lambda f: os.path.getctime(os.path.join(data_dir, f)))\n",
    "    file_path = os.path.join(data_dir, latest_file)\n",
    "    \n",
    "    print(f\"üìà Loading data from: {latest_file}\")\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Load performance data\n",
    "performance_df = load_latest_data()\n",
    "\n",
    "if performance_df is not None:\n",
    "    print(f\"‚úÖ Loaded {len(performance_df)} data points\")\n",
    "    print(f\"üìÖ Time range: {performance_df['timestamp'].min()} to {performance_df['timestamp'].max()}\")\n",
    "    print(f\"‚è±Ô∏è  Duration: {(performance_df['timestamp'].max() - performance_df['timestamp'].min()).total_seconds():.0f} seconds\")\n",
    "    \n",
    "    # Display basic statistics\n",
    "    print(\"\\nüìã Data Overview:\")\n",
    "    display(performance_df.head())\n",
    "    \n",
    "    print(\"\\nüìä Container Distribution:\")\n",
    "    container_counts = performance_df['container_name'].value_counts()\n",
    "    display(container_counts)\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No performance data available. Please run monitoring first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea811fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate performance statistics\n",
    "if performance_df is not None:\n",
    "    print(\"üìä Performance Statistics Summary:\\n\")\n",
    "    \n",
    "    # Group by container for analysis\n",
    "    stats_by_container = performance_df.groupby('container_name').agg({\n",
    "        'container_cpu_percent': ['mean', 'std', 'min', 'max'],\n",
    "        'container_memory_usage_mb': ['mean', 'std', 'min', 'max'],\n",
    "        'container_memory_percent': ['mean', 'std', 'min', 'max'],\n",
    "        'container_healthy': ['mean']  # Percentage of time healthy\n",
    "    }).round(2)\n",
    "    \n",
    "    # Flatten column names\n",
    "    stats_by_container.columns = ['_'.join(col).strip() for col in stats_by_container.columns]\n",
    "    stats_by_container = stats_by_container.rename(columns={\n",
    "        'container_healthy_mean': 'health_percentage'\n",
    "    })\n",
    "    \n",
    "    display(stats_by_container)\n",
    "    \n",
    "    # Create summary comparison\n",
    "    print(\"\\nüèÜ Performance Comparison (Lower is Better for CPU/Memory):\")\n",
    "    \n",
    "    summary_stats = []\n",
    "    for container in performance_df['container_name'].unique():\n",
    "        container_data = performance_df[performance_df['container_name'] == container]\n",
    "        \n",
    "        runtime_name = container.replace('-nextjs-app', '').replace('-', ' ').title()\n",
    "        \n",
    "        summary_stats.append({\n",
    "            'Runtime': runtime_name,\n",
    "            'Avg CPU (%)': container_data['container_cpu_percent'].mean(),\n",
    "            'Avg Memory (MB)': container_data['container_memory_usage_mb'].mean(),\n",
    "            'Avg Memory (%)': container_data['container_memory_percent'].mean(),\n",
    "            'CPU Stability (œÉ)': container_data['container_cpu_percent'].std(),\n",
    "            'Memory Stability (œÉ)': container_data['container_memory_usage_mb'].std(),\n",
    "            'Health %': (container_data['container_healthy'].mean() * 100),\n",
    "            'Data Points': len(container_data)\n",
    "        })\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_stats).round(2)\n",
    "    \n",
    "    # Sort by average CPU usage\n",
    "    summary_df = summary_df.sort_values('Avg CPU (%)')\n",
    "    display(summary_df)\n",
    "    \n",
    "    # Determine winners\n",
    "    print(\"\\nü•á Performance Winners:\")\n",
    "    print(f\"   Lowest CPU Usage: {summary_df.iloc[0]['Runtime']} ({summary_df.iloc[0]['Avg CPU (%)']}%)\")\n",
    "    print(f\"   Lowest Memory Usage: {summary_df.loc[summary_df['Avg Memory (MB)'].idxmin(), 'Runtime']} ({summary_df['Avg Memory (MB)'].min():.1f} MB)\")\n",
    "    print(f\"   Most Stable CPU: {summary_df.loc[summary_df['CPU Stability (œÉ)'].idxmin(), 'Runtime']} (œÉ = {summary_df['CPU Stability (œÉ)'].min():.2f})\")\n",
    "    print(f\"   Best Health Score: {summary_df.loc[summary_df['Health %'].idxmax(), 'Runtime']} ({summary_df['Health %'].max():.1f}%)\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Cannot calculate statistics - no performance data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14a3941",
   "metadata": {},
   "source": [
    "## 8. Visualize Results\n",
    "\n",
    "Create comprehensive visualizations to compare the performance characteristics of each runtime:\n",
    "\n",
    "- **Time Series Plots**: CPU and memory usage over time\n",
    "- **Box Plots**: Distribution of resource usage\n",
    "- **Bar Charts**: Average performance metrics comparison\n",
    "- **Correlation Analysis**: Relationship between CPU and memory usage\n",
    "- **Performance Dashboard**: Interactive multi-metric view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f77945c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualizations\n",
    "if performance_df is not None:\n",
    "    \n",
    "    # Set up color palette for runtimes\n",
    "    runtime_colors = {\n",
    "        'node-nextjs-app': '#68A063',    # Node.js green\n",
    "        'deno-nextjs-app': '#000000',    # Deno black  \n",
    "        'bun-nextjs-app': '#FBF0DF'      # Bun cream\n",
    "    }\n",
    "    \n",
    "    # 1. Time Series Plot - CPU Usage\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=('CPU Usage Over Time', 'Memory Usage Over Time', \n",
    "                       'CPU Usage Distribution', 'Memory Usage Distribution'),\n",
    "        specs=[[{\"secondary_y\": False}, {\"secondary_y\": False}],\n",
    "               [{\"secondary_y\": False}, {\"secondary_y\": False}]]\n",
    "    )\n",
    "    \n",
    "    # CPU time series\n",
    "    for container in performance_df['container_name'].unique():\n",
    "        container_data = performance_df[performance_df['container_name'] == container]\n",
    "        runtime_name = container.replace('-nextjs-app', '').replace('-', ' ').title()\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=container_data['timestamp'],\n",
    "                y=container_data['container_cpu_percent'],\n",
    "                mode='lines+markers',\n",
    "                name=f'{runtime_name} CPU',\n",
    "                line=dict(color=runtime_colors.get(container, '#1f77b4')),\n",
    "                showlegend=True\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        \n",
    "        # Memory time series\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=container_data['timestamp'],\n",
    "                y=container_data['container_memory_usage_mb'],\n",
    "                mode='lines+markers',\n",
    "                name=f'{runtime_name} Memory',\n",
    "                line=dict(color=runtime_colors.get(container, '#1f77b4'), dash='dot'),\n",
    "                showlegend=True\n",
    "            ),\n",
    "            row=1, col=2\n",
    "        )\n",
    "        \n",
    "        # CPU distribution\n",
    "        fig.add_trace(\n",
    "            go.Box(\n",
    "                y=container_data['container_cpu_percent'],\n",
    "                name=f'{runtime_name}',\n",
    "                marker_color=runtime_colors.get(container, '#1f77b4'),\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=2, col=1\n",
    "        )\n",
    "        \n",
    "        # Memory distribution  \n",
    "        fig.add_trace(\n",
    "            go.Box(\n",
    "                y=container_data['container_memory_usage_mb'],\n",
    "                name=f'{runtime_name}',\n",
    "                marker_color=runtime_colors.get(container, '#1f77b4'),\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=2, col=2\n",
    "        )\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        height=800,\n",
    "        title_text=\"Next.js Runtime Performance Comparison\",\n",
    "        title_x=0.5,\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    # Update axes labels\n",
    "    fig.update_xaxes(title_text=\"Time\", row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"Time\", row=1, col=2)\n",
    "    fig.update_xaxes(title_text=\"Runtime\", row=2, col=1)\n",
    "    fig.update_xaxes(title_text=\"Runtime\", row=2, col=2)\n",
    "    \n",
    "    fig.update_yaxes(title_text=\"CPU Usage (%)\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Memory Usage (MB)\", row=1, col=2)\n",
    "    fig.update_yaxes(title_text=\"CPU Usage (%)\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Memory Usage (MB)\", row=2, col=2)\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Cannot create visualizations - no performance data available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920ebcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create performance comparison charts\n",
    "if performance_df is not None:\n",
    "    \n",
    "    # Prepare data for comparison charts\n",
    "    comparison_data = []\n",
    "    for container in performance_df['container_name'].unique():\n",
    "        container_data = performance_df[performance_df['container_name'] == container]\n",
    "        runtime_name = container.replace('-nextjs-app', '').replace('-', ' ').title()\n",
    "        \n",
    "        comparison_data.append({\n",
    "            'Runtime': runtime_name,\n",
    "            'Avg_CPU': container_data['container_cpu_percent'].mean(),\n",
    "            'Avg_Memory_MB': container_data['container_memory_usage_mb'].mean(),\n",
    "            'Avg_Memory_Pct': container_data['container_memory_percent'].mean(),\n",
    "            'CPU_Std': container_data['container_cpu_percent'].std(),\n",
    "            'Memory_Std': container_data['container_memory_usage_mb'].std()\n",
    "        })\n",
    "    \n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    \n",
    "    # Create matplotlib subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('Performance Comparison: Node.js vs Deno vs Bun', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Color scheme\n",
    "    colors = ['#68A063', '#000000', '#FBF0DF']  # Node, Deno, Bun\n",
    "    \n",
    "    # 1. Average CPU Usage\n",
    "    bars1 = axes[0, 0].bar(comparison_df['Runtime'], comparison_df['Avg_CPU'], color=colors)\n",
    "    axes[0, 0].set_title('Average CPU Usage (%)')\n",
    "    axes[0, 0].set_ylabel('CPU Usage (%)')\n",
    "    axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, value in zip(bars1, comparison_df['Avg_CPU']):\n",
    "        axes[0, 0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,\n",
    "                       f'{value:.1f}%', ha='center', va='bottom')\n",
    "    \n",
    "    # 2. Average Memory Usage\n",
    "    bars2 = axes[0, 1].bar(comparison_df['Runtime'], comparison_df['Avg_Memory_MB'], color=colors)\n",
    "    axes[0, 1].set_title('Average Memory Usage (MB)')\n",
    "    axes[0, 1].set_ylabel('Memory Usage (MB)')\n",
    "    axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, value in zip(bars2, comparison_df['Avg_Memory_MB']):\n",
    "        axes[0, 1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
    "                       f'{value:.0f}MB', ha='center', va='bottom')\n",
    "    \n",
    "    # 3. CPU Stability (Lower standard deviation = more stable)\n",
    "    bars3 = axes[1, 0].bar(comparison_df['Runtime'], comparison_df['CPU_Std'], color=colors)\n",
    "    axes[1, 0].set_title('CPU Usage Stability (Lower = Better)')\n",
    "    axes[1, 0].set_ylabel('Standard Deviation')\n",
    "    axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, value in zip(bars3, comparison_df['CPU_Std']):\n",
    "        axes[1, 0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                       f'{value:.2f}', ha='center', va='bottom')\n",
    "    \n",
    "    # 4. Memory Stability\n",
    "    bars4 = axes[1, 1].bar(comparison_df['Runtime'], comparison_df['Memory_Std'], color=colors)\n",
    "    axes[1, 1].set_title('Memory Usage Stability (Lower = Better)')\n",
    "    axes[1, 1].set_ylabel('Standard Deviation (MB)')\n",
    "    axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, value in zip(bars4, comparison_df['Memory_Std']):\n",
    "        axes[1, 1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n",
    "                       f'{value:.1f}MB', ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Performance ranking\n",
    "    print(\"üèÜ Performance Rankings:\\n\")\n",
    "    \n",
    "    # Rank by CPU usage (lower is better)\n",
    "    cpu_ranking = comparison_df.sort_values('Avg_CPU')[['Runtime', 'Avg_CPU']]\n",
    "    print(\"CPU Usage (Lower is Better):\")\n",
    "    for i, (_, row) in enumerate(cpu_ranking.iterrows(), 1):\n",
    "        medal = \"ü•á\" if i == 1 else \"ü•à\" if i == 2 else \"ü•â\"\n",
    "        print(f\"  {medal} {i}. {row['Runtime']}: {row['Avg_CPU']:.2f}%\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # Rank by memory usage (lower is better)\n",
    "    memory_ranking = comparison_df.sort_values('Avg_Memory_MB')[['Runtime', 'Avg_Memory_MB']]\n",
    "    print(\"Memory Usage (Lower is Better):\")\n",
    "    for i, (_, row) in enumerate(memory_ranking.iterrows(), 1):\n",
    "        medal = \"ü•á\" if i == 1 else \"ü•à\" if i == 2 else \"ü•â\"\n",
    "        print(f\"  {medal} {i}. {row['Runtime']}: {row['Avg_Memory_MB']:.1f} MB\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Cannot create comparison charts - no performance data available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96a9e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create correlation and efficiency analysis\n",
    "if performance_df is not None:\n",
    "    \n",
    "    print(\"üî¨ Advanced Performance Analysis:\\n\")\n",
    "    \n",
    "    # CPU vs Memory correlation analysis\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Scatter plot: CPU vs Memory for each runtime\n",
    "    for container in performance_df['container_name'].unique():\n",
    "        container_data = performance_df[performance_df['container_name'] == container]\n",
    "        runtime_name = container.replace('-nextjs-app', '').replace('-', ' ').title()\n",
    "        color = runtime_colors.get(container, '#1f77b4')\n",
    "        \n",
    "        axes[0].scatter(container_data['container_cpu_percent'], \n",
    "                       container_data['container_memory_usage_mb'],\n",
    "                       label=runtime_name, alpha=0.7, color=color, s=50)\n",
    "        \n",
    "        # Calculate correlation\n",
    "        correlation = container_data['container_cpu_percent'].corr(container_data['container_memory_usage_mb'])\n",
    "        print(f\"{runtime_name} CPU-Memory Correlation: {correlation:.3f}\")\n",
    "    \n",
    "    axes[0].set_xlabel('CPU Usage (%)')\n",
    "    axes[0].set_ylabel('Memory Usage (MB)')\n",
    "    axes[0].set_title('CPU vs Memory Usage Correlation')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Resource efficiency radar chart (using matplotlib)\n",
    "    # Calculate efficiency metrics (lower values = better efficiency)\n",
    "    efficiency_metrics = {}\n",
    "    for container in performance_df['container_name'].unique():\n",
    "        container_data = performance_df[performance_df['container_name'] == container]\n",
    "        runtime_name = container.replace('-nextjs-app', '').replace('-', ' ').title()\n",
    "        \n",
    "        # Normalize metrics (0-1 scale, lower is better)\n",
    "        avg_cpu = container_data['container_cpu_percent'].mean()\n",
    "        avg_memory = container_data['container_memory_usage_mb'].mean()\n",
    "        cpu_stability = container_data['container_cpu_percent'].std()\n",
    "        memory_stability = container_data['container_memory_usage_mb'].std()\n",
    "        \n",
    "        efficiency_metrics[runtime_name] = {\n",
    "            'CPU Usage': avg_cpu,\n",
    "            'Memory Usage': avg_memory / 100,  # Scale to similar range\n",
    "            'CPU Stability': cpu_stability,\n",
    "            'Memory Stability': memory_stability / 10  # Scale to similar range\n",
    "        }\n",
    "    \n",
    "    # Create efficiency comparison\n",
    "    metric_names = list(efficiency_metrics[list(efficiency_metrics.keys())[0]].keys())\n",
    "    x_pos = np.arange(len(metric_names))\n",
    "    width = 0.25\n",
    "    \n",
    "    for i, (runtime, metrics) in enumerate(efficiency_metrics.items()):\n",
    "        values = list(metrics.values())\n",
    "        color = ['#68A063', '#000000', '#FBF0DF'][i]\n",
    "        axes[1].bar(x_pos + i * width, values, width, label=runtime, color=color, alpha=0.8)\n",
    "    \n",
    "    axes[1].set_xlabel('Metrics')\n",
    "    axes[1].set_ylabel('Score (Lower = Better)')\n",
    "    axes[1].set_title('Resource Efficiency Comparison')\n",
    "    axes[1].set_xticks(x_pos + width)\n",
    "    axes[1].set_xticklabels(metric_names, rotation=45)\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate overall efficiency score\n",
    "    print(\"\\nüìä Overall Efficiency Scores (Lower = Better):\")\n",
    "    overall_scores = {}\n",
    "    for runtime, metrics in efficiency_metrics.items():\n",
    "        # Weighted average (equal weights for simplicity)\n",
    "        score = sum(metrics.values()) / len(metrics)\n",
    "        overall_scores[runtime] = score\n",
    "        \n",
    "    # Sort by efficiency (lower is better)\n",
    "    sorted_scores = sorted(overall_scores.items(), key=lambda x: x[1])\n",
    "    \n",
    "    for i, (runtime, score) in enumerate(sorted_scores, 1):\n",
    "        medal = \"ü•á\" if i == 1 else \"ü•à\" if i == 2 else \"ü•â\"\n",
    "        print(f\"  {medal} {i}. {runtime}: {score:.2f}\")\n",
    "    \n",
    "    print(f\"\\nüèÜ Most Efficient Runtime: {sorted_scores[0][0]}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Cannot perform advanced analysis - no performance data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28ccace",
   "metadata": {},
   "source": [
    "## Summary and Conclusions\n",
    "\n",
    "This notebook provides a comprehensive comparison of Next.js performance across three JavaScript runtimes. Based on the analysis, you can make informed decisions about which runtime best fits your specific needs.\n",
    "\n",
    "### Key Insights:\n",
    "\n",
    "1. **CPU Performance**: Shows which runtime uses the least CPU resources under load\n",
    "2. **Memory Efficiency**: Identifies the most memory-efficient runtime \n",
    "3. **Stability**: Measures consistency of resource usage over time\n",
    "4. **Health/Reliability**: Tracks application uptime and responsiveness\n",
    "\n",
    "### How to Use This Analysis:\n",
    "\n",
    "- **For Production Deployment**: Choose the runtime with the best overall efficiency and stability\n",
    "- **For Development**: Consider the balance between performance and developer experience\n",
    "- **For Scaling**: Focus on the runtime with the most predictable resource usage patterns\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **Load Testing**: Run this analysis under different load conditions\n",
    "2. **Extended Monitoring**: Monitor for longer periods to identify trends\n",
    "3. **Real-World Scenarios**: Test with actual application workloads\n",
    "4. **Cost Analysis**: Consider infrastructure costs based on resource usage\n",
    "\n",
    "The performance characteristics may vary based on your specific application, traffic patterns, and infrastructure setup."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
